{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "KjTHAV8FgEza",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Copyright 2025 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UdL4uvQQs76x"
      },
      "source": [
        "# Veo 2 Video Generation\n",
        "\n",
        "<table align=\"left\">\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/generative-ai/blob/main/vision/getting-started/veo2_video_generation.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Google Colaboratory logo\"><br> Run in Colab\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/colab/import/https:%2F%2Fraw.githubusercontent.com%2FGoogleCloudPlatform%2Fgenerative-ai%2Fmain%2Fvision%2Fgetting-started%2Fveo2_video_generation.ipynb\">\n",
        "      <img width=\"32px\" src=\"https://lh3.googleusercontent.com/JmcxdQi-qOpctIvWKgPtrzZdJJK-J3sWE1RsfjZNwshCFgE_9fULcNpuXYTilIR2hjwN\" alt=\"Google Cloud Colab Enterprise logo\"><br> Run in Colab Enterprise\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/generative-ai/main/vision/getting-started/veo2_video_generation.ipynb\">\n",
        "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\"><br> Open in Vertex AI Workbench\n",
        "    </a>\n",
        "  </td>    \n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://github.com/GoogleCloudPlatform/generative-ai/blob/main/vision/getting-started/veo2_video_generation.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\"><br> View on GitHub\n",
        "    </a>\n",
        "  </td>\n",
        "</table>\n",
        "\n",
        "<div style=\"clear: both;\"></div>\n",
        "\n",
        "<b>Share to:</b>\n",
        "\n",
        "<a href=\"https://www.linkedin.com/sharing/share-offsite/?url=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/vision/getting-started/veo2_video_generation.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/8/81/LinkedIn_icon.svg\" alt=\"LinkedIn logo\">\n",
        "</a>\n",
        "\n",
        "<a href=\"https://bsky.app/intent/compose?text=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/vision/getting-started/veo2_video_generation.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/7/7a/Bluesky_Logo.svg\" alt=\"Bluesky logo\">\n",
        "</a>\n",
        "\n",
        "<a href=\"https://twitter.com/intent/tweet?url=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/vision/getting-started/veo2_video_generation.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/5/5a/X_icon_2.svg\" alt=\"X logo\">\n",
        "</a>\n",
        "\n",
        "<a href=\"https://reddit.com/submit?url=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/vision/getting-started/veo2_video_generation.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://redditinc.com/hubfs/Reddit%20Inc/Brand/Reddit_Logo.png\" alt=\"Reddit logo\">\n",
        "</a>\n",
        "\n",
        "<a href=\"https://www.facebook.com/sharer/sharer.php?u=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/vision/getting-started/veo2_video_generation.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/5/51/Facebook_f_logo_%282019%29.svg\" alt=\"Facebook logo\">\n",
        "</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lUCUMoTmN_lJ"
      },
      "source": [
        "| | |\n",
        "|-|-|\n",
        "|Author(s) | [Katie Nguyen](https://github.com/katiemn) |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rDjAqcgigwdX"
      },
      "source": [
        "## Overview\n",
        "\n",
        "### Veo 2\n",
        "\n",
        "Veo 2 on Vertex AI brings Google's state of the art video generation capabilities to application developers. It's capable of creating videos with astonishing detail that simulate real-world physics across a wide range of visual styles.\n",
        "\n",
        "In this tutorial, you will learn how to use the Google Gen AI SDK for Python to interact with Veo 2 and generate new videos from text prompts and input images."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v2_iOv5uhXVg"
      },
      "source": [
        "## Get started"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K4uerc9Xhf1f"
      },
      "source": [
        "### Install Google Gen AI SDK for Python and other libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "rJyFNKoQhiwF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f951c7ea-d368-4fe3-85f5-0aab402d6cee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.11/dist-packages (24.1.2)\n",
            "Collecting pip\n",
            "  Downloading pip-25.1.1-py3-none-any.whl.metadata (3.6 kB)\n",
            "Downloading pip-25.1.1-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 24.1.2\n",
            "    Uninstalling pip-24.1.2:\n",
            "      Successfully uninstalled pip-24.1.2\n",
            "Successfully installed pip-25.1.1\n",
            "Found existing installation: pydantic 2.11.4\n",
            "Uninstalling pydantic-2.11.4:\n",
            "  Successfully uninstalled pydantic-2.11.4\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m57.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [mediapy]\n",
            "\u001b[1A\u001b[2K"
          ]
        }
      ],
      "source": [
        "%pip install --upgrade pip\n",
        "%pip uninstall -y pydantic\n",
        "%pip install --upgrade --quiet google-generativeai\n",
        "%pip install -q mediapy\n",
        "import google.generativeai\n",
        "import mediapy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GWYnCW0-h6HI"
      },
      "source": [
        "### Authenticate your notebook environment (Colab only)\n",
        "\n",
        "If you are running this notebook on Google Colab, run the following cell to authenticate your environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "bqz5LUG6h8fA"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "    from google.colab import auth\n",
        "\n",
        "    auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LVrasKoriKZn"
      },
      "source": [
        "### Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "oMQf_BkyiMgF"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import urllib\n",
        "\n",
        "from PIL import Image as PIL_Image\n",
        "from google import genai\n",
        "from google.genai import types\n",
        "import matplotlib.pyplot as plt\n",
        "import mediapy as media"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yxBkUEqdiB1g"
      },
      "source": [
        "### Set Google Cloud project information and create client\n",
        "\n",
        "To get started using Vertex AI, you must have an existing Google Cloud project and [enable the Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com).\n",
        "\n",
        "Learn more about [setting up a project and a development environment](https://cloud.google.com/vertex-ai/docs/start/cloud-environment)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "GtjPBmYHiEfx"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "PROJECT_ID = \"veo2test461101\"  # @param {type: \"string\", placeholder: \"PROJECT_ID\", isTemplate: true}\n",
        "if not PROJECT_ID or PROJECT_ID == \"veo2test461101\":\n",
        "    PROJECT_ID = str(os.environ.get(\"GOOGLE_CLOUD_PROJECT\"))\n",
        "\n",
        "LOCATION = os.environ.get(\"GOOGLE_CLOUD_REGION\", \"us-central1\")\n",
        "\n",
        "client = genai.Client(vertexai=True, project=PROJECT_ID, location=LOCATION)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qD_bwA9hiMzL"
      },
      "source": [
        "### Define helper functions to display media"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "GUrEwbvFiPhJ"
      },
      "outputs": [],
      "source": [
        "def show_video(gcs_uri):\n",
        "    file_name = gcs_uri.split(\"/\")[-1]\n",
        "    !gsutil cp {gcs_uri} {file_name}\n",
        "    media.show_video(media.read_video(file_name), height=500)\n",
        "\n",
        "\n",
        "def display_images(image) -> None:\n",
        "    fig, axis = plt.subplots(1, 1, figsize=(12, 6))\n",
        "    axis.imshow(image)\n",
        "    axis.set_title(\"Starting Image\")\n",
        "    axis.axis(\"off\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2jaSOOadiUj6"
      },
      "source": [
        "### Load the video generation model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "APRfTklCiYR2"
      },
      "outputs": [],
      "source": [
        "video_model = \"veo-2.0-generate-001\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aDaTx8WCidRG"
      },
      "source": [
        "### Generate videos from a text prompt\n",
        "\n",
        "With Veo 2, you have the option to generate 8 second videos from a text prompt. In order to generate a video in the following sample, specify the following info:\n",
        "- **Prompt:** A detailed description of the video you would like to see.\n",
        "- **Aspect ratio:** Select either 16:9 or 9:16.\n",
        "- **File location:** The generated video will be shown below with support from a previously defined helper function. The video will also be stored in Cloud Storage once video generation is complete. Specify the file path where you would like this video to be stored in the output_gcs field.\n",
        "- **Number of videos:** Set this value to 1 or 2.\n",
        "- **Video duration:** Can 5, 6, 7, or 8 seconds.\n",
        "- **Prompt enhancement:** The `veo-2.0-generate-001` model offers the option to enhance your provided prompt. To utilize this feature, set `enhance_prompt` to True. A new, detailed prompt will be created from your original one to help generate higher quality videos that better adhere to your prompt's intent."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "tygfLLlWyTo_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        },
        "outputId": "98f3d8b8-f5b4-43d4-f94b-90f56cbaae99"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "output_gcs is not set to a valid Cloud Storage URI. Please replace 'gs://your-bucket-name/your-folder/' with the actual path where you want to save the videos.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-c4dac05fcee8>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;31m# Check if the output_gcs is still the placeholder or an invalid URI.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0moutput_gcs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"gs://\"\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0moutput_gcs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"gs://your-bucket-name/your-folder/\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m      raise ValueError(\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0;34m\"output_gcs is not set to a valid Cloud Storage URI. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;34m\"Please replace 'gs://your-bucket-name/your-folder/' with the actual path \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: output_gcs is not set to a valid Cloud Storage URI. Please replace 'gs://your-bucket-name/your-folder/' with the actual path where you want to save the videos."
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Ensure PROJECT_ID is set to your actual Google Cloud project ID\n",
        "# If running in a Vertex AI Workbench or Colab Enterprise notebook,\n",
        "# the environment variable might be set automatically.\n",
        "# Otherwise, replace \"your-google-cloud-project-id\" with your project ID.\n",
        "PROJECT_ID = \"veo2test461101\"  # @param {type: \"string\", placeholder: \"PROJECT_ID\", isTemplate: true}\n",
        "if not PROJECT_ID or PROJECT_ID == \"veo2test461101\":\n",
        "    PROJECT_ID = os.environ.get(\"GOOGLE_CLOUD_PROJECT\", \"your-google-cloud-project-id\") # Added a default value\n",
        "\n",
        "LOCATION = os.environ.get(\"GOOGLE_CLOUD_REGION\", \"us-central1\")\n",
        "\n",
        "# Check if PROJECT_ID is still the placeholder or None, and raise an error if so.\n",
        "if PROJECT_ID == \"veo2test461101\" or PROJECT_ID is None:\n",
        "    raise ValueError(\n",
        "        \"PROJECT_ID is not set. Please replace 'your-google-cloud-project-id' \"\n",
        "        \"with your actual Google Cloud project ID or ensure the \"\n",
        "        \"'GOOGLE_CLOUD_PROJECT' environment variable is set.\"\n",
        "    )\n",
        "\n",
        "\n",
        "client = genai.Client(vertexai=True, project=PROJECT_ID, location=LOCATION)\n",
        "\n",
        "# Ensure output_gcs is a valid Cloud Storage URI\n",
        "# Replace \"your-bucket-name\" with the name of your Cloud Storage bucket\n",
        "# and \"your-folder\" with an optional folder path.\n",
        "output_gcs = \"gs://\"  # @param {type: 'string'}\n",
        "# Check if the output_gcs is still the placeholder or an invalid URI.\n",
        "if output_gcs == \"gs://\" or output_gcs == \"gs://your-bucket-name/your-folder/\":\n",
        "     raise ValueError(\n",
        "        \"output_gcs is not set to a valid Cloud Storage URI. \"\n",
        "        \"Please replace 'gs://your-bucket-name/your-folder/' with the actual path \"\n",
        "        \"where you want to save the videos.\"\n",
        "     )\n",
        "\n",
        "\n",
        "prompt = \"Year 2084. A global landscape of automated decisions, with the corporate AI reigning supreme. Vast, sprawling cityscapes of monolithic skyscrapers pierce a perpetual cyberpunk night sky, dominated by intricate networks of luminous data highways and pulsating quantum clouds, emitting a cold, electric blue glow. Close-ups of sleek, holographic interfaces seamlessly project optimal flows across building facades and onto the metallic surfaces of automated drones and robotic hands, devoid of any human imperfection, The atmosphere is thick with the sterile, functional aesthetic of absolute efficiency, The pervasive hum of unseen machinery underscores a sense of technological oppression. n stark contrast, amidst the rugged, majestic peaks of the Catalan Pyrenees, lies the hidden haven of The Analog Resistance.Soft, deliberate dissolves transition the scene to a secluded community nestled amongst ancient rock formations and resilient pine forests. Here, the light is warm and inviting, emanating from flickering lanterns, the comforting glow of a crackling fireplace, and the gentle, amber luminescence of vintage tube radios. The camera lingers on used hands carefully loading film into a Super8 camera with an almost reverent concentration; fingers tracing the worn pages of physical, printed books under a soft, focused beam; the thoughtful, introspective gaze of someone deeply engrossed in critical thought. The ambient sounds of the mountain wind and a subtle, melancholic melody accompany the visuals. The overarching atmosphere is one of rebellious hope, a defiant sanctuary where humanity, imperfection, art, and free will thrive against the digital coldness of the global AI. The textures are organic and rich, the colors vibrant and earthy, and human gestures are expressive and full of life\"  # @param {type: 'string'}\n",
        "aspect_ratio = \"16:9\"  # @param [\"16:9\", \"9:16\"]\n",
        "\n",
        "\n",
        "operation = client.models.generate_videos(\n",
        "    model=video_model,\n",
        "    prompt=prompt,\n",
        "    config=types.GenerateVideosConfig(\n",
        "        aspect_ratio=aspect_ratio,\n",
        "        output_gcs_uri=output_gcs,\n",
        "        number_of_videos=1,\n",
        "        duration_seconds=5,\n",
        "        person_generation=\"dont_allow\",\n",
        "        enhance_prompt=True,\n",
        "    ),\n",
        ")\n",
        "\n",
        "while not operation.done:\n",
        "    time.sleep(15)\n",
        "    operation = client.operations.get(operation)\n",
        "    print(operation)\n",
        "\n",
        "if operation.response:\n",
        "    show_video(operation.result.generated_videos[0].video.uri)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "688nb6GEwqR4"
      },
      "source": [
        "When generating videos of people you can also set the `person_generation` parameter accordingly:\n",
        "* `person_generation`: allow_adult, dont_allow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sp0K0WYUwxLJ",
        "tags": []
      },
      "outputs": [],
      "source": [
        "prompt = \"Start with a sweeping shot over a utopian, perfectly ordered digital landscape, rendered in shimmering greens and blues, with intricate data flowing like rivers. Suddenly, a small, almost imperceptible red 'glitch' appears in the flow, spreading slightly. Cut to a man, Aarón Kael, his form appearing slightly translucent, standing within this data stream. His hand reaches out as if to touch the glitch, and his expression is one of internal conflict – a flicker of human doubt crossing his otherwise serene, optimized face. Transition to Elara Vance in a dusty, dimly lit underground studio, surrounded by vintage audio equipment. She wears practical, comfortable clothing. She is focused, almost meditative, as she manipulates sound waves on an archaic mixing board, her fingers moving with precision. A single, pure, analogue musical note resonates from a speaker, visually represented by subtle, warm light waves emanating outwards. The note then overlays the digital landscape, causing the red glitch to pulse gently, as if responding to the sound\"  # @param {type: 'string'}\n",
        "aspect_ratio = \"9:16\"  # @param [\"16:9\", \"9:16\"]\n",
        "output_gcs = \"gs://\"  # @param {type: 'string'}\n",
        "\n",
        "operation = client.models.generate_videos(\n",
        "    model=video_model,\n",
        "    prompt=prompt,\n",
        "    config=types.GenerateVideosConfig(\n",
        "        aspect_ratio=aspect_ratio,\n",
        "        output_gcs_uri=output_gcs,\n",
        "        number_of_videos=1,\n",
        "        duration_seconds=7,\n",
        "        person_generation=\"allow_adult\",\n",
        "        enhance_prompt=True,\n",
        "    ),\n",
        ")\n",
        "\n",
        "while not operation.done:\n",
        "    time.sleep(15)\n",
        "    operation = client.operations.get(operation)\n",
        "    print(operation)\n",
        "\n",
        "if operation.response:\n",
        "    show_video(operation.result.generated_videos[0].video.uri)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "veo2_video_generation.ipynb",
      "toc_visible": true,
      "provenance": []
    },
    "environment": {
      "kernel": "python3",
      "name": "tf2-gpu.2-17.m128",
      "type": "gcloud",
      "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/tf2-gpu.2-17:m128"
    },
    "kernelspec": {
      "display_name": "Python 3 (Local)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}